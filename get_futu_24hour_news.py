#!/usr/bin/env python3
import requests
import pandas as pd
from datetime import datetime, timezone, timedelta
import pytz
import time
import random

URL = "https://news.futunn.com/news-site-api/main/get-flash-list"
OUTPUT_FILE = "futu_flash_news.csv"
PAGE_SIZE = 50
TOTAL_NEWS = 10000  # è®¾ç½®ä¸€ä¸ªè¾ƒå¤§çš„ä¸Šé™ï¼Œå®é™…ä¸Šä¼šç”±æ—¶é—´æ¡ä»¶ç»ˆæ­¢

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                  "AppleWebKit/537.36 (KHTML, like Gecko) "
                  "Chrome/120.0 Safari/537.36",
    "Referer": "https://news.futunn.com/",
    "Accept": "application/json, text/plain, */*",
}

def get_target_time_range():
    """
    è·å–ç›®æ ‡æ—¶é—´èŒƒå›´ï¼š
    yesterday_start: æ˜¨å¤© 00:00:00 (æœ¬åœ°æ—¶é—´)
    yesterday_end:   ä»Šå¤© 00:00:00 (æœ¬åœ°æ—¶é—´)
    è¿”å›æ—¶é—´æˆ³èŒƒå›´
    """
    now = datetime.now()
    today_start = now.replace(hour=0, minute=0, second=0, microsecond=0)
    yesterday_start = today_start - timedelta(days=1)
    
    # è½¬æ¢ä¸ºæ—¶é—´æˆ³
    ts_start = int(yesterday_start.timestamp())
    ts_end = int(today_start.timestamp())
    
    return ts_start, ts_end

def ts_to_us_eastern(ts_str):
    """æŠŠ Unix æ—¶é—´æˆ³è½¬ä¸ºç¾ä¸œæ—¶é—´ï¼ˆè‡ªåŠ¨å¤„ç†å¤ä»¤æ—¶ï¼‰"""
    try:
        ts = int(ts_str)
        dt_utc = datetime.fromtimestamp(ts, tz=timezone.utc)
        eastern = pytz.timezone("America/New_York")
        dt_est = dt_utc.astimezone(eastern)
        return dt_est.strftime("%Y-%m-%d %H:%M:%S %Z")
    except Exception:
        return ""

def fetch_news(limit=TOTAL_NEWS):
    all_news = []
    seq_mark = ""
    retry = 0
    
    ts_start, ts_end = get_target_time_range()
    print(f"ğŸ¯ ç›®æ ‡æ—¶é—´èŒƒå›´: {datetime.fromtimestamp(ts_start)} è‡³ {datetime.fromtimestamp(ts_end)}")

    while len(all_news) < limit:
        params = {"pageSize": PAGE_SIZE, "_t": int(time.time() * 1000)}
        if seq_mark:
            params["seqMark"] = seq_mark

        resp = requests.get(URL, headers=HEADERS, params=params, timeout=10)
        if resp.status_code != 200:
            print(f"âŒ è¯·æ±‚å¤±è´¥ HTTP {resp.status_code}")
            break

        if not resp.text.strip():
            retry += 1
            if retry > 3:
                print("âš ï¸ è¿ç»­è¿”å›ç©ºå“åº”ï¼Œæ”¾å¼ƒã€‚")
                break
            print(f"âš ï¸ ç©ºå“åº”ï¼Œç¬¬ {retry} æ¬¡é‡è¯• ...")
            time.sleep(2 + random.random())
            continue

        try:
            data = resp.json()
        except Exception:
            print("âš ï¸ æ— æ³•è§£æ JSONï¼Œå¯èƒ½è¢«é™æµæˆ–è¿”å›ç©ºã€‚ç¨åé‡è¯•ã€‚")
            time.sleep(2 + random.random())
            continue

        items = data.get("data", {}).get("data", {}).get("news", [])
        seq_mark = data.get("data", {}).get("data", {}).get("seqMark")
        
        if not items:
            print("âš ï¸ æ²¡æœ‰æ›´å¤šæ•°æ®æˆ–è¢«å±è”½ã€‚")
            break
            
        # æ£€æŸ¥æœ¬æ‰¹æ¬¡æœ€æ—§çš„ä¸€æ¡æ–°é—»æ—¶é—´
        last_item_time = int(items[-1].get("time"))
        
        # è¿‡æ»¤ç¬¦åˆæ—¶é—´èŒƒå›´çš„æ–°é—»
        for item in items:
            item_time = int(item.get("time"))
            if ts_start <= item_time < ts_end:
                all_news.append(item)
        
        print(f"âœ… å·²æŠ“å– {len(all_news)} æ¡ç¬¦åˆæ¡ä»¶çš„æ–°é—» (å½“å‰æ‰¹æ¬¡æœ€æ—§æ—¶é—´: {datetime.fromtimestamp(last_item_time)}) ...")
        
        # å¦‚æœå½“å‰æ‰¹æ¬¡æœ€æ—§çš„æ—¶é—´å·²ç»æ—©äºæ˜¨å¤©çš„å¼€å§‹æ—¶é—´ï¼Œè¯´æ˜å·²ç»è·å–åˆ°äº†è¶³å¤Ÿçš„æ•°æ®ï¼Œå¯ä»¥åœæ­¢äº†
        if last_item_time < ts_start:
            print("ğŸ å·²åˆ°è¾¾æ˜¨å¤©ä¹‹å‰çš„æ•°æ®ï¼Œåœæ­¢æŠ“å–ã€‚")
            break

        if not data.get("data", {}).get("data", {}).get("hasMore"):
            break

        time.sleep(1.2 + random.random() * 0.8)

    return all_news

if __name__ == "__main__":
    print("ğŸ“° æ­£åœ¨æŠ“å–å¯Œé€”å¿«è®¯...")
    news_list = fetch_news()

    if not news_list:
        print("âŒ æ²¡æŠ“åˆ°ä»»ä½•æ–°é—»ã€‚")
        exit(1)

    df = pd.DataFrame([
        {
            "id": item.get("id"),
            "time_us_eastern": ts_to_us_eastern(item.get("time")),
            "title": item.get("title")
                or item.get("brief")
                or item.get("summary")
                or (item.get("content") or "").split("ã€‚")[0],
            "summary": (
                item.get("summary")
                or item.get("brief")
                or (item.get("content") or "")[:120]
            ),
            "source": item.get("sourceName"),
            "url": item.get("detailUrl") or f"https://news.futunn.com/post/{item.get('id')}",
        }
        for item in news_list
    ])

    df.to_csv(OUTPUT_FILE, index=False, encoding="utf-8-sig")
    print(f"âœ… å·²ä¿å­˜ {OUTPUT_FILE}ï¼Œå…± {len(df)} æ¡å¿«è®¯ï¼ˆæ—¶é—´ä¸ºç¾ä¸œæ—¶åŒºï¼‰ã€‚")

